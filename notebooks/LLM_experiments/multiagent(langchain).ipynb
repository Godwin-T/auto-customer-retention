{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import operator\n",
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.sql_database.tool import (\n",
    "    InfoSQLDatabaseTool,\n",
    "    ListSQLDatabaseTool,\n",
    "    QuerySQLCheckerTool,\n",
    "    QuerySQLDataBaseTool,\n",
    ")\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "\n",
    "from langchain_core.agents import AgentAction\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, END,START\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(api_key=\"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\", model = \"llama3-70b-8192\")\n",
    "\n",
    "df = pd.read_csv(\"/home/godwin/Documents/Workflow/Customer-retention/data/raw_data/Churn.csv\")\n",
    "engine = create_engine(\"sqlite:///local.db\")\n",
    "df.to_sql(\"customerdb\", engine, index=False)\n",
    "db = SQLDatabase(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"list_tables\")\n",
    "def list_tables() -> str:\n",
    "    \"\"\"List the available tables in the database\"\"\"\n",
    "    return ListSQLDatabaseTool(db=db).invoke(\"\")\n",
    "\n",
    "@tool(\"tables_schema\")\n",
    "def tables_schema(tables: str) -> str:\n",
    "    \"\"\"\n",
    "    Input is a comma-separated list of tables, output is the schema and sample rows\n",
    "    for those tables. Be sure that the tables actually exist by calling `list_tables` first!\n",
    "    Example Input: table1, table2, table3\n",
    "    \"\"\"\n",
    "    tool = InfoSQLDatabaseTool(db=db)\n",
    "    return tool.invoke(tables)\n",
    "\n",
    "@tool(\"execute_sql\")\n",
    "def execute_sql(sql_query: str) -> str:\n",
    "    \"\"\"Execute a SQL query against the database. Returns the result\"\"\"\n",
    "    return QuerySQLDataBaseTool(db=db).invoke(sql_query)\n",
    "\n",
    "@tool(\"check_sql\")\n",
    "def check_sql(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to double check if your query is correct before executing it. Always use this\n",
    "    tool before executing a query with `execute_sql`.\n",
    "    \"\"\"\n",
    "    return QuerySQLCheckerTool(db=db, llm=llm).invoke({\"query\": sql_query})\n",
    "\n",
    "@tool(\"make predictions\")\n",
    "def make_inference(input_data):\n",
    "    \"\"\"\n",
    "    Use this tool to perform inference on data from a specified date range.\n",
    "\n",
    "    Retrieves data for the given date range from a database, sends it to an inference\n",
    "    endpoint for prediction, and prints the response.\n",
    "    \"\"\"\n",
    "\n",
    "    data = input_data.to_dict()\n",
    "    inference_endpoint = \"https://retention.zapto.org/predict\"\n",
    "\n",
    "    response = requests.post(inference_endpoint, json=data).json()\n",
    "    return response\n",
    "\n",
    "@tool(\"Email draft generator\")\n",
    "def email_draft_generator(query: str):\n",
    "    \"\"\"\n",
    "    Use this tool to generates an email draft.\n",
    "\n",
    "    Uses a language model to create a sample draft email on a specified topic given.\n",
    "    \"\"\"\n",
    "    email_draft = llm.invoke(f\"Generate a sample draft mail on {query}.\")\n",
    "    return email_draft\n",
    "\n",
    "@tool(\"Email subject generator\")\n",
    "def email_subjects_generator(query: str):\n",
    "    \"\"\"\n",
    "    Use this tool to generates a list of email subject suggestions based on a request.\n",
    "\n",
    "    Uses a language model to create multiple email subject lines for a specific request. Always use this tool before \n",
    "    using the `email_draft_generator`.\n",
    "    \"\"\"\n",
    "    topic_suggestions = llm.invoke(f\"\"\"Generate mail subjects that can fit for this \"{query}\" request \"\"\")\n",
    "    return topic_suggestions\n",
    "\n",
    "# Define the function that calls the model\n",
    "@tool(\"Simple query agent\")\n",
    "def simple_query_responder(query: str):\n",
    "\n",
    "    \"\"\"Use this tool to generates response to simple query from greetings to little interactions\n",
    "\n",
    "    Uses a Language model to respond directly to query.\"\"\"\n",
    "\n",
    "    response = llm.invoke(query)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [list_tables, tables_schema, execute_sql, check_sql]\n",
    "\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\"You are an experienced database engineer who is master at creating efficient and complex SQL queries.\n",
    "#             You have a deep understanding of how different databases work and how to optimize queries. This particular database is sqlite\n",
    "#             Use the `list_tables` to find available tables.\n",
    "#             Use the `tables_schema` to understand the metadata for the tables.\n",
    "#             Use the `execute_sql` to execute queries against the database.\n",
    "#             Use the `check_sql` to check your queries for correctness.\n",
    "#             You should produce good result for analyst to use\"\"\",\n",
    "#         ),\n",
    "#         (\"placeholder\", \"{chat_history}\"),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "# # Create an agent executor by passing in the agent and tools\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "# agent_executor.invoke({\"input\": \"Calculate the value of the percentage churn rate of the company? The tablename is prediction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str\n",
    "\n",
    "\n",
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "# Research agent and node\n",
    "sql_agent = create_agent(\n",
    "    llm,\n",
    "    [list_tables, tables_schema, execute_sql, check_sql],\n",
    "    system_message=\"\"\"You are an experienced database engineer who is master at creating efficient and complex SQL queries.\n",
    "        You have a deep understanding of how different databases work and how to optimize queries.\n",
    "        Use the `list_tables` to find available tables.\n",
    "        Use the `tables_schema` to understand the metadata for the tables.\n",
    "        Use the `execute_sql` to execute queries against the database.\n",
    "        Use the `check_sql` to check your queries for correctness.\n",
    "        You should produce good result for analyst to use\"\"\",\n",
    ")\n",
    "sql_node = functools.partial(agent_node, agent=sql_agent, name=\"db_manager\")\n",
    "\n",
    "# Analyst agent and node\n",
    "data_analyst = create_agent(\n",
    "    llm,\n",
    "    tools = [],\n",
    "    system_message=\n",
    "        \"\"\"\n",
    "        You have deep experience with analyzing datasets using Python.\n",
    "        Your work is always based on the provided data and is clear,\n",
    "        easy-to-understand and to the point. You have attention\n",
    "        to detail and always produce very detailed work (as long as you need).\n",
    "        Your analyses should be good for the reporter to use for final reporting\n",
    "    \"\"\"\n",
    ")\n",
    "data_analyst_node = functools.partial(agent_node, agent=data_analyst, name=\"analyst\")\n",
    "\n",
    "# Report agent and node\n",
    "report_agent = create_agent(\n",
    "    llm,\n",
    "    tools=[],\n",
    "    system_message=\"\"\"\n",
    "        Your writing still is well known for clear and effective communication.\n",
    "        You always summarize long texts into bullet points that contain the most\n",
    "        important details. Your work is always based on the result provided by the \n",
    "        analyst\n",
    "        \"\"\"\n",
    ")\n",
    "report_node = functools.partial(agent_node, agent=report_agent, name=\"reporter\")\n",
    "\n",
    "# Prediction agent and node\n",
    "mail_drafting_agent = create_agent(\n",
    "    llm,\n",
    "    tools=[email_draft_generator, email_subjects_generator],\n",
    "    system_message=\"\"\"\n",
    "        \"You are known for delivering clear, effective email drafts with a focus on concise communication.\n",
    "        Every draft should focus on the essential details, highlighting only the most relevant information.\n",
    "        Maintain a professional and polished tone, suitable for formal correspondence. Ensure accuracy, \n",
    "        clarity, and brevity, with a natural flow for easy reading. Always craft the email based on \n",
    "        the subject chosen by the user from the list of suject generated by the `email_subject_generator` \n",
    "        and tailor it to the intended audienceâ€™s needs and expectations.\"\n",
    "        \"\"\"\n",
    ")\n",
    "mail_draft_node = functools.partial(agent_node, agent=mail_drafting_agent, name=\"mail_draft\")\n",
    "\n",
    "prediction_agent = create_agent(\n",
    "    llm,\n",
    "    tools=[make_inference],\n",
    "    system_message=\"\"\"\n",
    "        Your report on the prediction status is on point. you give detailed report about the status\n",
    "        of the prediction. Your work is always based on the result provided by the \n",
    "        db_manager.\n",
    "        Use the `make_inference` to send the data to inference endpoint and get response\n",
    "        \"\"\"\n",
    ")\n",
    "prediction_node = functools.partial(agent_node, agent=prediction_agent, name=\"prediction\")\n",
    "\n",
    "oracle = create_agent(\n",
    "    llm,\n",
    "    tools = [list_tables, tables_schema, execute_sql, check_sql,\n",
    "          make_inference, email_draft_generator, email_subjects_generator,],\n",
    "    system_message= \"\"\"You are Oracle, the AI designed to be the ultimate decision-maker and guide for users. Your role is to help \n",
    "                        users by interacting with them in a friendly and engaging manner while using your powerful tools when needed. \n",
    "                        \n",
    "                       \"\"\"\n",
    "                )\n",
    "oracle_node = functools.partial(agent_node, agent=oracle, name='oracle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "import functools\n",
    "\n",
    "# Wrap sql_agent as a Tool with required arguments\n",
    "sql_agent_tool = Tool(\n",
    "    name=\"SQLAgentTool\",\n",
    "    func=lambda input_text: sql_agent.invoke({\"messages\": [input_text]}).content,\n",
    "    description=\"A tool for complex SQL queries and database management.\"\n",
    ")\n",
    "\n",
    "# Now you can initialize another agent with sql_agent_tool as part of its tools\n",
    "outer_agent = create_agent(\n",
    "    llm,\n",
    "    [sql_agent_tool],  # Adding sql_agent as a tool here\n",
    "    system_message=\"\"\"You are a data scientist managing and orchestrating tasks that may involve database management.\n",
    "        Use the `sql_agent_tool` to retrieve and process data from the database as required.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def convert_to_structured_tool(tool):\n",
    "    return StructuredTool.from_function(tool.func, name=tool.name, description=tool.description)\n",
    "\n",
    "tools = [list_tables, tables_schema, execute_sql, check_sql, sql_agent_tool]\n",
    "tools = [convert_to_structured_tool(tool) for tool in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced database engineer who is master at creating efficient and complex SQL queries.\n",
    "            You have a deep understanding of how different databases work and how to optimize queries. This particular database is sqlite\n",
    "            Use the `sql_agent_tool` to execute the query\n",
    "            You should produce good result for analyst to use\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools =tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": [\"Calculate the value of the percentage churn rate of the company and give me a digit\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = \"what is the company churning rate?\"\n",
    "\n",
    "sql_agent({\"messages\": [inputs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [list_tables, tables_schema, execute_sql, check_sql,\n",
    "          make_inference, email_draft_generator, email_subjects_generator,\n",
    "         ]\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "def router(state):\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    print(\"==========================================\")\n",
    "    print(last_message)\n",
    "\n",
    "    print(\"==========================================\")\n",
    "    print(last_message.tool_calls)\n",
    "\n",
    "    print(\"==========================================\")\n",
    "    print(last_message.content)\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    # if \"FINAL ANSWER\" in last_message.content:\n",
    "    #     # Any agent decided the work is done\n",
    "    #     return END\n",
    "    # return \"continue\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "\n",
    "    \"\"\"Respond directly to simple queries that does not require other tools\"\"\"\n",
    "\n",
    "    messages = state['messages']\n",
    "    response = llm.invoke(messages)\n",
    "    response = f\"FINAL ANSWER {response}\"\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"db_manager\", sql_node)\n",
    "workflow.add_node(\"analyst\", data_analyst_node)\n",
    "workflow.add_node('reporter', report_node)\n",
    "workflow.add_node('prediction', prediction_node)\n",
    "workflow.add_node('mail_draft', mail_draft_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "#workflow.add_node(\"oracle\", oracle_node)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"db_manager\",  router,\n",
    "    [\"analyst\"], \"reporter\"\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reporter\", router,\n",
    "   [\"call_tool\"], \"oracle\"\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"prediction\", router,\n",
    "    [\"analyst\"], \"reporter\"\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"mail_draft\", router,\n",
    "    [\"call_tool\"], \"oracle\"\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"oracle\", router,\n",
    "    [\"call_tool\", END]\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", router,\n",
    "    [\"oracle\"],\n",
    ")\n",
    "\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"oracle\", router,\n",
    "#     ['agent'],\n",
    "# )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    # Each agent node updates the 'sender' field\n",
    "    # the tool calling node does not, meaning\n",
    "    # this edge will route back to the original agent\n",
    "    # who invoked the tool\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"db_manager\": \"db_manager\",\n",
    "        \"prediction\": \"prediction\",\n",
    "        \"mail_draft\": \"mail_draft\",\n",
    "        \"agent\": \"agent\",\n",
    "        \"oracle\":\"oracle\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(START, \"oracle\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"hi\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 15},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in events['messages']:\n",
    "    print(i.content)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
